{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"li ul li{ list-style-type: lower-alpha; } Last updated on Feb 17, 2023 Coresets and Coreset Trees \u00a4 A Coreset is a weighted subset of samples from a larger dataset, selected in such a way that the selected samples maintain the statistical properties and corner cases of the full dataset such that training an algorithm on the Coreset will yield the same results as training that same algorithm on the full dataset. The DataHeroes library can be used to build a Coreset as well as to build and maintain a more complex Coreset Structure, known as a Coreset Tree. Once the Coreset or Coreset tree is built, various data science operations can be performed on it, such as training a model, updating labels and removing samples. Unlike a Coreset which is built over the entire dataset in one iteration, a Coreset Tree is comprised of multiple Coresets, each built separately for a chunk (batch) of the dataset ( chunk_size ) and then combined iteratively in a tree-like manner. In the illustration below, the entire dataset was split into 8 chunks, of 10K instances each (X1, \u2026, X8) and a Coreset of up to 1K samples ( coreset_size ) was built for each chunk separately (C1, C2, C4, \u2026, C12). Every pair of Coresets is then combined into a new Coreset, in a tree-like hierarchy, with the root being the minimal subset, called the root Coreset (C15). The Coreset Tree data structure has several advantages over a single Coreset computed over the entire dataset: A single Coreset requires the entire dataset to fit into the device\u2019s memory and is therefore limited in the size of datasets it can handle. A Coreset Tree, does not have this limitation as it processes the dataset in chunks and can therefore handle any dataset size by splitting the data into the appropriate number of chunks. A Coreset Tree can be computed much faster since the Coresets\u2019 computation can be distributed across a cluster of devices or processors. In a Coreset Tree, additional data can be added to the original dataset without requiring re-computation of the entire Coreset Tree. A Coreset just needs to be built for the additional data and then that Coreset is added to the Coreset Tree, while updating only the necessary Coreset nodes on the path to the root Coreset. This makes it a great structure to use for model maintenance in production. Similarly, updating the target or features of existing instances or removing instances, does not require re\u2011computation of the entire Coreset Tree, updating the Coreset nodes on the path to the root Coreset will suffice. E.g.: If we updated the target for some instances in X6, all we need to do to keep the Coreset Tree updated, is to update the Coresets C9, C10, C14 and C15, while the rest of the Coresets remain unchanged. The main disadvantage of the Coreset Tree versus a single Coreset computed over the entire dataset, is that each level of the Coreset tree increases the approximation error, therefore leading to a slightly less accurate root Coreset. However, this error can be controlled and decreased easily, by increasing the coreset_size . Another disadvantage of the Coreset tree versus a single Coreset is that in every level of the tree we lose some \u201coutliers\u201d which are not carried over from the previous level down. Hence the more levels a tree has, the less \u201coutliers\u201d remain in its root coreset. This can be controlled as well by indicating to the build() function when building the Coreset, whether it should be optimized for training (more levels) or for cleaning (a single level). Building a Coreset or Coreset Tree \u00a4 The class representing the Coreset Tree in the DataHeroes library is named CoresetTreeService. While the chunk_size and coreset_size can be passed as parameters to the class, the default behavior is for them to be automatically calculated by the class when the Coreset is built based on the quadruplet: \u2018number of\u00ad instances\u2019, \u2018number of features\u2019 (deduced from the dataset), \u2018number of classes\u2019 (if passed, otherwise deduced from the dataset) and the \u2018memory\u2019 (if passed, otherwise deduced based on the device\u2019s memory). Based on this quadruplet the class will also decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset. In the case of a single Coreset, every time additional data is added to the class using the partial_build function, the class will assess whether it is worth moving to an actual Coreset Tree, and will automatically convert the structure as necessary. To build the Coreset Tree, use the standard build() function or one of its sibling functions \u2013 build_from_df() or build_from_file() . See the build options tutorial here. Data Cleaning Use Case \u00a4 You can use a Coreset property referred to as Importance (or Sensitivity) to systematically identify potential errors and anomalies in your data. When building a Coreset, every instance in the data is assigned an Importance value, which indicates how important it is to the final machine learning model. Instances that receive a high Importance value in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. This version allows you to find the important samples in the dataset, regardless of what algorithm you use to train your model. To review data instances based on their importance, first build a Coreset using any build() function, while setting the parameter optimized_for to 'cleaning', then use the get_important_samples() function to get the samples with the highest importance, for the classes of interest. When you find incorrectly labeled samples, use the update_targets() function to update their labels or remove the samples using the remove_samples() function. Any such change to the samples will automatically update the Coreset data structure to reflect the changes. Should you prefer to suppress these updates until you finish all your changes, set the force_do_nothing flag to True when calling the update_targets() or remove_samples() functions and call the update_dirty() function to update the Coreset data structure when you\u2019re ready. More advanced cleaning techniques can be applied by using filters with the filter_out_samples() function. When cleaning, it is important to remember that both the train and test dataset should be cleaned to maintain a high quality, non-biased test. See data cleaning tutorials here. Training and Hyperparameter Tuning Use Case \u00a4 Using our much smaller Coreset structure, you can train or tune your model orders of magnitude faster and consume significantly less compute resources and energy, compared to using the full dataset. Use the DataHeroes\u2019 library fit() function to fit a model on the Coreset and the predict() function to run predictions on the model. Alternatively, if you prefer to use other libraries for training, use the get_coreset() function to retrieve a numpy array or pandas dataframe version of the Coreset which can be used with other libraries. To check the quality of your Coreset, you can fit a model and compare its predictions to predictions from a model built using your full dataset. To decrease the approximation error in the case of a Coreset Tree, requesting level 1 or 2 instead of the default level 0 when calling get_coreset() will return the requested level from the Coreset Tree. The current version provides a Coreset optimized for training with the logistic regression algorithm (upcoming versions will provide additional Coresets optimized for other algorithms). To build the Coreset or Coreset Tree use any build() function to build the CoresetTreeServiceLG, while setting the parameter optimized_for to 'training\u2019. See the tutorial explaining the usage of functions in the library here. Model Maintenance Use Case \u00a4 You can use the Coreset Tree structure to update models in production when new data comes in, by updating the Coreset Tree with the new data and training the model on the Coreset, without having to re-train the model on the full dataset. After building the Coreset Tree using one of the build() functions, you can add additional data to the Coreset Tree using the partial_build() function or one of its sibling functions partial_build_from_df() and partial_build_from_file() , and retrain the model as explained above. Getting Started \u00a4 Create a free account on https://dataheroes.ai/getting-started/ . Install the library on your device by running: pip install dataheroes . Activate your account by executing the following code once (from each device you\u2019re using): from dataheroes.utils import activate_account activate_account(\"john.doe@gmail.com\") Check out our documentation and examples available here . Other library dependencies \u00a4 The DataHeroes library has dependency on other libraries. Please note that when installing the DataHeroes library, older versions of other libraries you may be using, may get automatically updated. The table below shows the minimum version required from each library the dataheroes library depends on. Library Minimum Version numpy 1.19.0 scipy 1.7.0 scikit-learn 0.24.0 pandas 1.0.0 joblib 0.15.0 threadpoolctl 2.1.0 networkx 2.5 pydot 1.4.1 matplotlib 3.3.0 opentelemetry-sdk 1.14.0 opentelemetry-api 1.14.0 opentelemetry-exporter-otlp 1.14.0 psutil 5.8.0 licensing 0.31 tables 3.6.1","title":"Release Notes - Version 0.1.1"},{"location":"#coresets-and-coreset-trees","text":"A Coreset is a weighted subset of samples from a larger dataset, selected in such a way that the selected samples maintain the statistical properties and corner cases of the full dataset such that training an algorithm on the Coreset will yield the same results as training that same algorithm on the full dataset. The DataHeroes library can be used to build a Coreset as well as to build and maintain a more complex Coreset Structure, known as a Coreset Tree. Once the Coreset or Coreset tree is built, various data science operations can be performed on it, such as training a model, updating labels and removing samples. Unlike a Coreset which is built over the entire dataset in one iteration, a Coreset Tree is comprised of multiple Coresets, each built separately for a chunk (batch) of the dataset ( chunk_size ) and then combined iteratively in a tree-like manner. In the illustration below, the entire dataset was split into 8 chunks, of 10K instances each (X1, \u2026, X8) and a Coreset of up to 1K samples ( coreset_size ) was built for each chunk separately (C1, C2, C4, \u2026, C12). Every pair of Coresets is then combined into a new Coreset, in a tree-like hierarchy, with the root being the minimal subset, called the root Coreset (C15). The Coreset Tree data structure has several advantages over a single Coreset computed over the entire dataset: A single Coreset requires the entire dataset to fit into the device\u2019s memory and is therefore limited in the size of datasets it can handle. A Coreset Tree, does not have this limitation as it processes the dataset in chunks and can therefore handle any dataset size by splitting the data into the appropriate number of chunks. A Coreset Tree can be computed much faster since the Coresets\u2019 computation can be distributed across a cluster of devices or processors. In a Coreset Tree, additional data can be added to the original dataset without requiring re-computation of the entire Coreset Tree. A Coreset just needs to be built for the additional data and then that Coreset is added to the Coreset Tree, while updating only the necessary Coreset nodes on the path to the root Coreset. This makes it a great structure to use for model maintenance in production. Similarly, updating the target or features of existing instances or removing instances, does not require re\u2011computation of the entire Coreset Tree, updating the Coreset nodes on the path to the root Coreset will suffice. E.g.: If we updated the target for some instances in X6, all we need to do to keep the Coreset Tree updated, is to update the Coresets C9, C10, C14 and C15, while the rest of the Coresets remain unchanged. The main disadvantage of the Coreset Tree versus a single Coreset computed over the entire dataset, is that each level of the Coreset tree increases the approximation error, therefore leading to a slightly less accurate root Coreset. However, this error can be controlled and decreased easily, by increasing the coreset_size . Another disadvantage of the Coreset tree versus a single Coreset is that in every level of the tree we lose some \u201coutliers\u201d which are not carried over from the previous level down. Hence the more levels a tree has, the less \u201coutliers\u201d remain in its root coreset. This can be controlled as well by indicating to the build() function when building the Coreset, whether it should be optimized for training (more levels) or for cleaning (a single level).","title":"Coresets and Coreset Trees"},{"location":"#building-a-coreset-or-coreset-tree","text":"The class representing the Coreset Tree in the DataHeroes library is named CoresetTreeService. While the chunk_size and coreset_size can be passed as parameters to the class, the default behavior is for them to be automatically calculated by the class when the Coreset is built based on the quadruplet: \u2018number of\u00ad instances\u2019, \u2018number of features\u2019 (deduced from the dataset), \u2018number of classes\u2019 (if passed, otherwise deduced from the dataset) and the \u2018memory\u2019 (if passed, otherwise deduced based on the device\u2019s memory). Based on this quadruplet the class will also decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset. In the case of a single Coreset, every time additional data is added to the class using the partial_build function, the class will assess whether it is worth moving to an actual Coreset Tree, and will automatically convert the structure as necessary. To build the Coreset Tree, use the standard build() function or one of its sibling functions \u2013 build_from_df() or build_from_file() . See the build options tutorial here.","title":"Building a Coreset or Coreset Tree"},{"location":"#data-cleaning-use-case","text":"You can use a Coreset property referred to as Importance (or Sensitivity) to systematically identify potential errors and anomalies in your data. When building a Coreset, every instance in the data is assigned an Importance value, which indicates how important it is to the final machine learning model. Instances that receive a high Importance value in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. This version allows you to find the important samples in the dataset, regardless of what algorithm you use to train your model. To review data instances based on their importance, first build a Coreset using any build() function, while setting the parameter optimized_for to 'cleaning', then use the get_important_samples() function to get the samples with the highest importance, for the classes of interest. When you find incorrectly labeled samples, use the update_targets() function to update their labels or remove the samples using the remove_samples() function. Any such change to the samples will automatically update the Coreset data structure to reflect the changes. Should you prefer to suppress these updates until you finish all your changes, set the force_do_nothing flag to True when calling the update_targets() or remove_samples() functions and call the update_dirty() function to update the Coreset data structure when you\u2019re ready. More advanced cleaning techniques can be applied by using filters with the filter_out_samples() function. When cleaning, it is important to remember that both the train and test dataset should be cleaned to maintain a high quality, non-biased test. See data cleaning tutorials here.","title":"Data Cleaning Use Case"},{"location":"#training-and-hyperparameter-tuning-use-case","text":"Using our much smaller Coreset structure, you can train or tune your model orders of magnitude faster and consume significantly less compute resources and energy, compared to using the full dataset. Use the DataHeroes\u2019 library fit() function to fit a model on the Coreset and the predict() function to run predictions on the model. Alternatively, if you prefer to use other libraries for training, use the get_coreset() function to retrieve a numpy array or pandas dataframe version of the Coreset which can be used with other libraries. To check the quality of your Coreset, you can fit a model and compare its predictions to predictions from a model built using your full dataset. To decrease the approximation error in the case of a Coreset Tree, requesting level 1 or 2 instead of the default level 0 when calling get_coreset() will return the requested level from the Coreset Tree. The current version provides a Coreset optimized for training with the logistic regression algorithm (upcoming versions will provide additional Coresets optimized for other algorithms). To build the Coreset or Coreset Tree use any build() function to build the CoresetTreeServiceLG, while setting the parameter optimized_for to 'training\u2019. See the tutorial explaining the usage of functions in the library here.","title":"Training and Hyperparameter Tuning Use Case"},{"location":"#model-maintenance-use-case","text":"You can use the Coreset Tree structure to update models in production when new data comes in, by updating the Coreset Tree with the new data and training the model on the Coreset, without having to re-train the model on the full dataset. After building the Coreset Tree using one of the build() functions, you can add additional data to the Coreset Tree using the partial_build() function or one of its sibling functions partial_build_from_df() and partial_build_from_file() , and retrain the model as explained above.","title":"Model Maintenance Use Case"},{"location":"#getting-started","text":"Create a free account on https://dataheroes.ai/getting-started/ . Install the library on your device by running: pip install dataheroes . Activate your account by executing the following code once (from each device you\u2019re using): from dataheroes.utils import activate_account activate_account(\"john.doe@gmail.com\") Check out our documentation and examples available here .","title":"Getting Started"},{"location":"#other-library-dependencies","text":"The DataHeroes library has dependency on other libraries. Please note that when installing the DataHeroes library, older versions of other libraries you may be using, may get automatically updated. The table below shows the minimum version required from each library the dataheroes library depends on. Library Minimum Version numpy 1.19.0 scipy 1.7.0 scikit-learn 0.24.0 pandas 1.0.0 joblib 0.15.0 threadpoolctl 2.1.0 networkx 2.5 pydot 1.4.1 matplotlib 3.3.0 opentelemetry-sdk 1.14.0 opentelemetry-api 1.14.0 opentelemetry-exporter-otlp 1.14.0 psutil 5.8.0 licensing 0.31 tables 3.6.1","title":"Other library dependencies"},{"location":"README-DEPLOY/","text":"Documentation deployment \u00a4 During execution GitHub credentials will be asked (you need enter token as password). pip install -r requirements_mkdocs.txt mkdocs gh-deploy --force","title":"README DEPLOY"},{"location":"README-DEPLOY/#documentation-deployment","text":"During execution GitHub credentials will be asked (you need enter token as password). pip install -r requirements_mkdocs.txt mkdocs gh-deploy --force","title":"Documentation deployment"},{"location":"tutorials/","text":"Example Dataset Type Description Data Cleaning: Coreset vs Random Image Classification Comparing cleaning the CIFAR-10 dataset using the dataheroes library vs. cleaning it randomly. Data Cleaning + Labeling Utility Image Classification Providing a simple utility, allowing to display the pictures and correct their labels using the dataheroes library, demonstrated on CIFAR-10. Data Cleaning Object Detection Demonstrating cleaning the COCO object detection dataset using the dataheroes library. Data Cleaning Image Classification Demonstrating cleaning the ImageNet dataset using the dataheroes library. Build Options Tabular Demonstrating different possibilities to construct the Coreset tree data structure. All Library Functions Tabular Demonstrating the usage of all library functions available for the Coreset tree data structure. Configuration File - An example configuration file.","title":"Tutorials"},{"location":"reference/SUMMARY/","text":"services coreset_tree kmeans lg lr pca svd","title":"SUMMARY"},{"location":"reference/services/coreset_tree/kmeans/","text":"CoresetTreeServiceKMeans \u00a4 CoresetTreeServiceKMeans ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for KMeans. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None build \u00a4 build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self filter_out_samples \u00a4 filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator. get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results. predict_proba \u00a4 predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model. print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"kmeans"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans","text":"CoresetTreeServiceKMeans ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for KMeans. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None","title":"CoresetTreeServiceKMeans"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.build","text":"build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.filter_out_samples","text":"filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"filter_out_samples()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator.","title":"fit()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue.","title":"get_important_samples()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.is_dirty","text":"is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing.","title":"is_dirty()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.partial_build","text":"partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results.","title":"predict()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.predict_proba","text":"predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model.","title":"predict_proba()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"remove_samples()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None","title":"update_dirty()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_features()"},{"location":"reference/services/coreset_tree/kmeans/#services.coreset_tree.kmeans.CoresetTreeServiceKMeans.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_targets()"},{"location":"reference/services/coreset_tree/lg/","text":"CoresetTreeServiceLG \u00a4 CoresetTreeServiceLG ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , n_classes = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceClassifierMixin , CoresetTreeServiceSupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for Logistic Regression. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'target': {'name': 'Cover_Type'}, 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None n_classes int int The total number of classes (labels). When not provided, will be deduced from the provided data. When multiple files are provided n_classes will be deduced based on the first file only. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None sample_all Iterable iterable, optional Relevant for classification tasks only. A list of classes for which all instances should be taken, instead of applying sampling. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. For example: coreset_params = { \"class_weight\": {\"a\": 0.5, \"b\": 0.5} } None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None build \u00a4 build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self filter_out_samples \u00a4 filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator. get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False , inverse_class_weight = True ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False inverse_class_weight bool boolean, default True True - return weights / class_weights. False - return weights as they are. Relevant only for classification tasks and only if class_weight was passed in the coreset_params when initializing the class. True Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size. \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 3 parameters as input: indices, X, y and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results. predict_proba \u00a4 predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model. print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"lg"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG","text":"CoresetTreeServiceLG ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , n_classes = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceClassifierMixin , CoresetTreeServiceSupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for Logistic Regression. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'target': {'name': 'Cover_Type'}, 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None n_classes int int The total number of classes (labels). When not provided, will be deduced from the provided data. When multiple files are provided n_classes will be deduced based on the first file only. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None sample_all Iterable iterable, optional Relevant for classification tasks only. A list of classes for which all instances should be taken, instead of applying sampling. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. For example: coreset_params = { \"class_weight\": {\"a\": 0.5, \"b\": 0.5} } None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None","title":"CoresetTreeServiceLG"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.build","text":"build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.filter_out_samples","text":"filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"filter_out_samples()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator.","title":"fit()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False , inverse_class_weight = True ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False inverse_class_weight bool boolean, default True True - return weights / class_weights. False - return weights as they are. Relevant only for classification tasks and only if class_weight was passed in the coreset_params when initializing the class. True Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size. \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 3 parameters as input: indices, X, y and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue.","title":"get_important_samples()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.is_dirty","text":"is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing.","title":"is_dirty()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.partial_build","text":"partial_build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results.","title":"predict()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.predict_proba","text":"predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model.","title":"predict_proba()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"remove_samples()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None","title":"update_dirty()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_features()"},{"location":"reference/services/coreset_tree/lg/#services.coreset_tree.lg.CoresetTreeServiceLG.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_targets()"},{"location":"reference/services/coreset_tree/lr/","text":"CoresetTreeServiceLR \u00a4 CoresetTreeServiceLR ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceSupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for Linear Regression. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'target': {'name': 'Cover_Type'}, 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None build \u00a4 build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self filter_out_samples \u00a4 filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator. get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results. predict_proba \u00a4 predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model. print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"lr"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR","text":"CoresetTreeServiceLR ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceSupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for Linear Regression. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'target': {'name': 'Cover_Type'}, 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None","title":"CoresetTreeServiceLR"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.build","text":"build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.filter_out_samples","text":"filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"filter_out_samples()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator.","title":"fit()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue.","title":"get_important_samples()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.is_dirty","text":"is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing.","title":"is_dirty()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.partial_build","text":"partial_build ( X , y , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like An array or an iterator of targets. required indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results.","title":"predict()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.predict_proba","text":"predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model.","title":"predict_proba()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"remove_samples()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None","title":"update_dirty()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_features()"},{"location":"reference/services/coreset_tree/lr/#services.coreset_tree.lr.CoresetTreeServiceLR.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_targets()"},{"location":"reference/services/coreset_tree/pca/","text":"CoresetTreeServicePCA \u00a4 CoresetTreeServicePCA ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for PCA. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None build \u00a4 build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self filter_out_samples \u00a4 filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator. get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results. predict_proba \u00a4 predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model. print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"pca"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA","text":"CoresetTreeServicePCA ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for PCA. A service class for creating a coreset tree and working with it. optimized_for is a required parameter defining the main usage of the service: 'training' or 'cleaning'. In the 'cleaning' case, a single Coreset is built over the entire dataset. In the 'training' case, the service will decide whether to build an actual Coreset Tree or to build a single Coreset over the entire dataset, based on the quadruplet: n_instances, n_classes, max_memory_gb and the 'number of features' (deduced from the dataset). The chunk_size and coreset_size will be deduced based on the above quadruplet too. In case chunk_size and coreset_size are provided, they will override all above mentioned parameters (less recommended). If you intend passing class_weight to your classifier, it is recommended to pass it as a parameter to the class in coreset_params (see example below), so the coreset can be built while taking into account the class_weight. You can continue passing class_weight to your classifier, while retrieving the coreset using the get_coreset method with the parameter inverse_class_weight set to True (default). If you wish to stop passing class_weight to the classifier, retrieve the coreset using the get_coreset method with the parameter inverse_class_weight set to False. If you intend passing C (the inverse of regularization strength) to your solver, it should be adjusted as specified here when used on the Coreset: C = C * float(np.sum(weights) / len(X)) Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional The class used to interact with the provided data and store it locally. By default, only the sampled data is stored in HDF5 files format. None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. For Example: data_params = { 'index': {'name': 'index_column'} } None n_instances int int The total number of instances that are going to be processed (can be an estimation). This parameter is required and the only one from the above mentioned quadruplet, which isn't deduced from the data. None max_memory_gb int int, optional The maximum memory in GB that should be used. When not provided, the server's total memory is used. In any case only 80% of the provided memory or the server's total memory is considered. None optimized_for str str, either 'training' or 'cleaning'. The main usage of the service. required chunk_size int int, optional The number of instances to be used when creating a coreset node in the tree. When defined, it will override the parameters of optimized_for, n_instances, n_classes and max_memory_gb. chunk_size=0: nodes are created based on input chunks None coreset_size Union [ int , dict ] int, optional Represents the coreset size of each node in the coreset tree. The coreset is constructed by sampling data instances from the dataset based on their calculated importance. Since each instance may be sampled more than once, in practice, the actual size of the coreset is mostly smaller than coreset_size. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Coreset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level. None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function. None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None save_all bool Save all data to the database (not only selected samples). If passed default (None), it calculated on the base optimized_for parameter None","title":"CoresetTreeServicePCA"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.build","text":"build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.filter_out_samples","text":"filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"filter_out_samples()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator.","title":"fit()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue.","title":"get_important_samples()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.is_dirty","text":"is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing.","title":"is_dirty()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.partial_build","text":"partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results.","title":"predict()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.predict_proba","text":"predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model.","title":"predict_proba()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"remove_samples()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None","title":"update_dirty()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_features()"},{"location":"reference/services/coreset_tree/pca/#services.coreset_tree.pca.CoresetTreeServicePCA.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_targets()"},{"location":"reference/services/coreset_tree/svd/","text":"CoresetTreeServiceSVD \u00a4 CoresetTreeServiceSVD ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , n_classes = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for SVD build \u00a4 build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self filter_out_samples \u00a4 filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator. get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results. predict_proba \u00a4 predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model. print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"svd"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD","text":"CoresetTreeServiceSVD ( * , data_manager = None , data_params = None , n_instances = None , max_memory_gb = None , n_classes = None , optimized_for , chunk_size = None , coreset_size = None , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None , save_all = None ) Bases: CoresetTreeServiceUnsupervisedMixin , CoresetTreeService Subclass of CoresetTreeService for SVD","title":"CoresetTreeServiceSVD"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.build","text":"build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from parameters X, y and indices. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Create a coreset tree from pandas DataFrame(s). build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and target. Should include only one column. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Create a coreset tree based on data taken from local storage. build functions may be called only once. To add more data to the coreset tree use one of the build_partial functions. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when the dataset files are split to features and target. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.filter_out_samples","text":"filter_out_samples ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, based on the provided filter function. Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable , Iterable ], Iterable [ bool ]] function, optional A function that returns a list of indices to be removed from the tree. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of indices to be removed from the coreset tree. For example, in order to remove all instances with a target equal to 6, use the following function: filter_function = lambda indices, X, y : indices[y = 6]. required force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"filter_out_samples()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyperparameters kwargs Input when instantiating default model class. {} Returns: Type Description Fitted estimator.","title":"fit()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in its original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description Dict dict data: numpy arrays tuple (indices, X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , select_from_function = None , ignore_seen_samples = True ) Returns indices of samples in descending order of importance. Useful for identifying mislabeled instances. Either class_size (recommended) or size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None ignore_indices Iterable array-like, optional An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional An array of indices to consider when selecting important samples. None select_from_function Callable [[ Iterable , Iterable , Union [ Iterable , None], Union [ Iterable , None]], Iterable [ Any ]] function, optional. Pass a function in order to limit the selection of the important samples accordingly. The function should accept 4 parameters as input: indices, X, y, props and return a list(iterator) of the desired indices. None ignore_seen_samples bool bool, optional, default True Exclude already seen samples and set the seen flag on any indices returned by the function. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. Important samples indices. X: array-like[int]. X array. y: array-like[int]. y array. importance: array-like[float]. The importance property. Instances that receive a high Importance in the Coreset computation, require attention as they usually indicate a labeling error, anomaly, out-of-distribution problem or other data-related issue.","title":"get_important_samples()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.is_dirty","text":"is_dirty () boolean Type Description bool Indicates whether the coreset tree has nodes marked as dirty, bool meaning they were affected by any of the methods: bool remove_samples, update_targets, update_features or filter_out_samples, bool when they were called with force_do_nothing.","title":"is_dirty()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the subdirectory to load. When several subdirectories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen subdirectory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boolean, optional, default True If set, load saved buffer (a partial node of the tree) from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.partial_build","text":"partial_build ( X , y = None , indices = None , props = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like An array or an iterator of features. required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of targets. None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator with indices of X. None props Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional An array or an iterator of properties. None chunk_size int, optional The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , chunk_size = None , chunk_by = None , copy = False ) Add new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or a DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None chunk_size int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None copy bool boolean, default False False (default) - input data might be updated as result a consequence action like update_targets or update_features True - Data is copied before processing (impacts memory). False Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , reader_chunk_size_param_name = None , chunk_size = None , chunk_by = None ) Add new samples to a coreset tree based on data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None reader_chunk_size_param_name str str, optional reader_f input parameter name for reading file in chunks. When not provided we'll try to figure it out our self. Based on the data, we decide on the optimal chunk size to read and use this parameter as input when calling reader_f. Use \"ignore\" to skip the automatic chunk reading logic. None chunk_size int int, optional, default previous used chunk_size The number of instances used when creating a coreset node in the tree. chunk_size=0: nodes are created based on input chunks. None chunk_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data according to the provided key. When provided, chunk_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features. required Returns: Type Description Model prediction results.","title":"predict()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.predict_proba","text":"predict_proba ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Returns the probability of the sample for each class in the model.","title":"predict_proba()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be removed from the coreset tree. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"remove_samples()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to be restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the subdirectory where the data will be stored. None save_buffer bool boolean, default True Save also the data in the buffer (a partial node of the tree) along with the rest of the saved data. True override bool bool, optional, default False False: add a timestamp suffix so each save won\u2019t override the previous ones. True: The existing subdirectory with the provided name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2*coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only to the provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Calculate the sensitivity and resample the nodes that were marked as dirty, meaning they were affected by any of the methods: remove_samples, update_targets, update_features or filter_out_samples, when they were called with force_do_nothing. Parameters: Name Type Description Default force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None","title":"update_dirty()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the features for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable array-like An array of indices to be updated. required X Iterable array-like An array of features. Should have the same length as indices. required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int int, optional Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool bool, optional, default False When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_features()"},{"location":"reference/services/coreset_tree/svd/#services.coreset_tree.svd.CoresetTreeServiceSVD.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update the targets for selected samples on the coreset tree. Parameters: Name Type Description Default indices Iterable An array of indices to be updated. required y Iterable An array of classes/labels. Should have the same length as indices. required force_resample_all int Force full resampling of the affected nodes in the coreset tree, starting from level=force_resample_all. None - Do not force_resample_all (default), 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_sensitivity_recalc int Force the recalculation of the sensitivity and partial resampling of the affected nodes, based on the coreset's quality, starting from level=force_sensitivity_recalc. None - If self.save_all=False - one level above leaf node level. If self.save_all=True - leaf level 0 - The head of the tree, 1 - The level below the head of the tree, len(tree)-1 = leaf level, -1 - same as leaf level. None force_do_nothing bool When set to True, suppresses any update to the coreset tree until update_dirty is called. False","title":"update_targets()"},{"location":"coverage/","text":"article h1, article > a, .md-sidebar--secondary { display: none !important; } var coviframe = document.getElementById(\"coviframe\"); function resizeIframe() { coviframe.style.height = coviframe.contentWindow.document.documentElement.offsetHeight + 'px'; } coviframe.contentWindow.document.body.onclick = function() { coviframe.contentWindow.location.reload(); }","title":"Coverage"}]}