{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"skcoreset \u00a4 Installation \u00a4 For developers install the [dev] version. Go to the root folder and run: pip install . pip install .[dev] or to track local live changes: pip install -e . pip install -e .[dev] API \u00a4 Modules : skcoreset.sampling = Coresets are here skcoreset.sklearn_extra = Extra implementations of scikit-learn algorithms (such as weighted variants) skcoreset.tree = The tree data structure skcoreset.database = Database classes Coresets API \u00a4 Very similar to scikit-learn's api with extra hyperparameters such as: coreset_size: int | list = number of samples to sample sensitivity: str = some algorithms can use different sensitivities. To specify it use this parameters. To get extra information about algorithms read the docstring or call: ? AlgorithmName Relevant attributes .idxs , .weights = indexes and weights of the last built coreset Relevant methods .build(X, y, w, ...) -- Builds the coreset by selecting indexes and corresponding weights get_indexes_weights() -- returns indexes and weights .sample(...) -- to sample. For now it's used internaly Base class : All coresets inherit from the CoresetBase class that implements the build(...), .sample(...) method or from each other (Ex: CoresetPCA inherits from CoresetSVD ) Example \u00a4 # ... sklearn, numpy imports from skcoreset.sampling import CoresetReg # Get data X , y = fetch_california_housing ( return_X_y = True ) X = StandardScaler () . fit_transform ( X ) coreset_size = 1000 # Train and predict cor = CoresetReg ( coreset_size = coreset_size , sensitivity = \"lp\" ) idxs , weights = cor . build ( X , y = y ) reg = LinearRegression () reg . fit ( X [ idxs , :], y [ idxs ], sample_weight = weights ) mean_squared_error ( y , reg . predict ( X ) Tree API \u00a4 Logic : Tree-like structure that is built from the leaves to the root New data comes in. When the number of new samples exceeds buffer_size we start our coreset process. We split the data into nodes of sample_size . From each node we sample coreset_size samples when we reach a multiple of leaf_factor nodes ( leaf_factor is the number of children a parent node will have) we start to construct the parent as follows: gather data from sons and aggregate it coreset from what we've gathered We create a new node and add it to the tree How do we store the tree? The node data is stored in a Node dataclass that has the following attributes .indexes = the indexes in the database of the selected samples .weights = the corresponding weights n_represents = the number of samples the node represents Init Arguments: sample_size: int -- leaf level sample size. coreset_size: int| list -- coreset_size when sampling. List for multiclass buffer_size: int -- Buffer Size for memory sampling_list: int -- a list of coreset functions (Only the first is used for now) database: TreeDatabase | NumpyDatabase -- database to connect | a schema to init the TreeDatabase. leaf_factor: int` -- How many children / node Internal tree representation The internal tree is kept in the .tree atrribute The tree is constructed like a list of lists => [[leaf level], [one above], ..., [root level]] Therefore, leaves are at .tree[0] and the root at .tree[-1] We identify a node by the level and its index Relevant methods .read_data(start=0, end=None) = reads data between the start and end indexes. If the number of samples read exceed buffer_size the coreset process is started. This is the heavy lifting function .fit(level = 0) -- fits the model on a level of the tree (0 = root level) Example \u00a4 # ... sklearn, numpy etc imports from skcoreset.sampling import CoresetSVD from skcoreset.tree import Tree from skcoreset.database import NumpyDatabase # Get data X , y = fetch_kddcup99 ( return_X_y = True ) X = X [:, 4 :] . astype ( np . float64 ) k = 10 sample_size = 20000 coreset_size = 1000 buffer_size = sample_size # For ease of use we set it the same # The coreset type we want to use sampling_list = [ CoresetSVD ( k , coreset_size = coreset_size , replace = True )] database = NumpyDatabase ( X ) tree = Tree ( database = database , sample_size = sample_size , coreset_size = coreset_size , buffer_size = buffer_size , sampling_list = sampling_list , leaf_factor = 2 ) tree . read_data () tree . fit () Database \u00a4 Since the tree is keeping track of indexes in a db he must be given a db wrapper. We use the TreeDatabase or NumpyDatabase wrappers These implement the following methods: get_by_index(ind) = gets data given a list of indexes is_active(ind) = returns a list of True / False for each index in the given list of indexes loop_item(num_samples=None, start=0,, end=None) = iterates between start and end indexes and yields a batch of num_samples of data More resources \u00a4 Check the Examples or tests folders Dev \u00a4 Formatting and linting \u00a4 We use black and flake8 for formatting and linting These are configured to run before every commit with pre-commit in .pre-commit-config.yaml and setup.cfg . Run pre-commit install once and then run pre-commit run --all-files to fix and check your files. black will format your code and flake8 will warn you with what you need to change to make the code cleaner","title":"Home"},{"location":"#skcoreset","text":"","title":"skcoreset"},{"location":"#installation","text":"For developers install the [dev] version. Go to the root folder and run: pip install . pip install .[dev] or to track local live changes: pip install -e . pip install -e .[dev]","title":"Installation"},{"location":"#api","text":"Modules : skcoreset.sampling = Coresets are here skcoreset.sklearn_extra = Extra implementations of scikit-learn algorithms (such as weighted variants) skcoreset.tree = The tree data structure skcoreset.database = Database classes","title":"API"},{"location":"#coresets-api","text":"Very similar to scikit-learn's api with extra hyperparameters such as: coreset_size: int | list = number of samples to sample sensitivity: str = some algorithms can use different sensitivities. To specify it use this parameters. To get extra information about algorithms read the docstring or call: ? AlgorithmName Relevant attributes .idxs , .weights = indexes and weights of the last built coreset Relevant methods .build(X, y, w, ...) -- Builds the coreset by selecting indexes and corresponding weights get_indexes_weights() -- returns indexes and weights .sample(...) -- to sample. For now it's used internaly Base class : All coresets inherit from the CoresetBase class that implements the build(...), .sample(...) method or from each other (Ex: CoresetPCA inherits from CoresetSVD )","title":"Coresets API"},{"location":"#example","text":"# ... sklearn, numpy imports from skcoreset.sampling import CoresetReg # Get data X , y = fetch_california_housing ( return_X_y = True ) X = StandardScaler () . fit_transform ( X ) coreset_size = 1000 # Train and predict cor = CoresetReg ( coreset_size = coreset_size , sensitivity = \"lp\" ) idxs , weights = cor . build ( X , y = y ) reg = LinearRegression () reg . fit ( X [ idxs , :], y [ idxs ], sample_weight = weights ) mean_squared_error ( y , reg . predict ( X )","title":"Example"},{"location":"#tree-api","text":"Logic : Tree-like structure that is built from the leaves to the root New data comes in. When the number of new samples exceeds buffer_size we start our coreset process. We split the data into nodes of sample_size . From each node we sample coreset_size samples when we reach a multiple of leaf_factor nodes ( leaf_factor is the number of children a parent node will have) we start to construct the parent as follows: gather data from sons and aggregate it coreset from what we've gathered We create a new node and add it to the tree How do we store the tree? The node data is stored in a Node dataclass that has the following attributes .indexes = the indexes in the database of the selected samples .weights = the corresponding weights n_represents = the number of samples the node represents Init Arguments: sample_size: int -- leaf level sample size. coreset_size: int| list -- coreset_size when sampling. List for multiclass buffer_size: int -- Buffer Size for memory sampling_list: int -- a list of coreset functions (Only the first is used for now) database: TreeDatabase | NumpyDatabase -- database to connect | a schema to init the TreeDatabase. leaf_factor: int` -- How many children / node Internal tree representation The internal tree is kept in the .tree atrribute The tree is constructed like a list of lists => [[leaf level], [one above], ..., [root level]] Therefore, leaves are at .tree[0] and the root at .tree[-1] We identify a node by the level and its index Relevant methods .read_data(start=0, end=None) = reads data between the start and end indexes. If the number of samples read exceed buffer_size the coreset process is started. This is the heavy lifting function .fit(level = 0) -- fits the model on a level of the tree (0 = root level)","title":"Tree API"},{"location":"#example_1","text":"# ... sklearn, numpy etc imports from skcoreset.sampling import CoresetSVD from skcoreset.tree import Tree from skcoreset.database import NumpyDatabase # Get data X , y = fetch_kddcup99 ( return_X_y = True ) X = X [:, 4 :] . astype ( np . float64 ) k = 10 sample_size = 20000 coreset_size = 1000 buffer_size = sample_size # For ease of use we set it the same # The coreset type we want to use sampling_list = [ CoresetSVD ( k , coreset_size = coreset_size , replace = True )] database = NumpyDatabase ( X ) tree = Tree ( database = database , sample_size = sample_size , coreset_size = coreset_size , buffer_size = buffer_size , sampling_list = sampling_list , leaf_factor = 2 ) tree . read_data () tree . fit ()","title":"Example"},{"location":"#database","text":"Since the tree is keeping track of indexes in a db he must be given a db wrapper. We use the TreeDatabase or NumpyDatabase wrappers These implement the following methods: get_by_index(ind) = gets data given a list of indexes is_active(ind) = returns a list of True / False for each index in the given list of indexes loop_item(num_samples=None, start=0,, end=None) = iterates between start and end indexes and yields a batch of num_samples of data","title":"Database"},{"location":"#more-resources","text":"Check the Examples or tests folders","title":"More resources"},{"location":"#dev","text":"","title":"Dev"},{"location":"#formatting-and-linting","text":"We use black and flake8 for formatting and linting These are configured to run before every commit with pre-commit in .pre-commit-config.yaml and setup.cfg . Run pre-commit install once and then run pre-commit run --all-files to fix and check your files. black will format your code and flake8 will warn you with what you need to change to make the code cleaner","title":"Formatting and linting"},{"location":"installation/","text":"Tables \u00a4 Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files.","title":"Installation"},{"location":"installation/#tables","text":"Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files.","title":"Tables"},{"location":"usage/","text":"Code \u00a4 Inline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code \"fences\" Sample text here... Syntax highlighting var foo = function ( bar ) { return bar ++ ; }; console . log ( foo ( 5 ));","title":"Usage"},{"location":"usage/#code","text":"Inline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code \"fences\" Sample text here... Syntax highlighting var foo = function ( bar ) { return bar ++ ; }; console . log ( foo ( 5 ));","title":"Code"},{"location":"reference/SUMMARY/","text":"services coreset_services tree_services","title":"SUMMARY"},{"location":"reference/services/coreset_services/","text":"CoresetService \u00a4 CoresetService ( * , data_manager = None , data_params = None , coreset_size = 0.05 , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None ) Bases: CoresetServiceBase Service class for creating and working with a coreset Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. None coreset_size Union [ int , dict , float ] int or float, optional, default 0.05 (5% of the data) Coreset size or relative portion of the data to sample. 0.05 coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Corset algorithm specific parameters. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None build \u00a4 build ( X , y = None , indices = None ) Create a coreset from a transformed dataset(s). Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None Returns: Type Description CoresetService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , ** params ) Create a coreset rom pandas DataFrame(s). Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None Returns: Type Description CoresetService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None ) Create a coreset based on the data taken from a local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None Returns: Type Description CoresetService self fit \u00a4 fit ( model = None , ** model_params ) Train a model for the selected coreset. Parameters: Name Type Description Default model object, optional. A model instance to train with coreset data. None model_params keywords arguments, optional. model initialization parameters. {} Returns: Type Description A trained model. get_coreset \u00a4 get_coreset () Get coreset indices and weights. Returns: Type Description Tuple [ Iterable , Iterable ] A tuple of indices and weights. indices: a numpy array of selected indices. weights: a numpy array of corresponding weights. get_coreset_data \u00a4 get_coreset_data ( as_orig = False , with_index = False ) Get coreset data either in a processed format or in the original format. Parameters: Name Type Description Default as_orig boolean, optional, default False Should the data be returned in it's original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description dict dict data: numpy arrays tuple (indices,X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , * , ignore_indices = None , select_from_indices = None ) Returns indices of most important samples order by importance. Useful for identifying miss-labeled instances. At least one of size, class_size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional. An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional. An array of indices to include when selecting important samples. None Returns: Name Type Description tuple Tuple [ Iterable [ int ], Iterable [ float ]] indices: array-like[int]. important samples indices. importance: array-like[float]. The important value. High value is more important. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] Local directory where service data is stored. required name str default service class name (lower case) The name prefix of the sub-directory to load. When more than one sub-directories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen sub-directory is the last saved. None data_manager DataManagerT When specified, input data manger will be used instead of restoring it from the saved configuration. None working_directory Union [ str , os . PathLike ] default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetService CoresetService object predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X array an array of features required Returns: Type Description Model prediction results save \u00a4 save ( dir_path = None , name = None , override = False ) save service configuration and relevant data to a local directory. Use this method when the service needs to restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] default self.working_directory A local directory for saving service's files. None name str default service class name (lower case) Name of the sub-directory where the data will be stored. None override bool False: add a timestamp suffix so each save won\u2019t override previous ones. True: existing sub-directory with that name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset_data \u00a4 save_coreset_data ( file_path , as_orig = False , with_index = False ) Save coreset data to a file along with coreset weights. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required as_orig bool boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index bool boolean, optional, default False Relevant only when as_orig=True. Save also index column. False CoresetServiceKMeans \u00a4 Bases: CoresetService Subclass of CoresetService for KMeans CoresetServiceLG \u00a4 Bases: CoresetService get_coreset \u00a4 get_coreset ( inverse = True ) Return the indexes and weights. If class_weights is provided and inverse = True the weights will be divided by the class weights, therefore requiring the user to pass class_weights again the fit function. Parameters: Name Type Description Default inverse True - return weights / class_weights False - return weights as they are. True Returns: Type Description Tuple [ Iterable , Iterable ] Tuple[Iterable, Iterable] idxs, weights CoresetServiceLR \u00a4 Bases: CoresetService Subclass of CoresetService for linear regression CoresetServicePCA \u00a4 Bases: CoresetService Subclass of CoresetService for PCA","title":"coreset_services"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService","text":"CoresetService ( * , data_manager = None , data_params = None , coreset_size = 0.05 , coreset_params = None , sample_all = None , working_directory = None , cache_dir = None ) Bases: CoresetServiceBase Service class for creating and working with a coreset Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. None coreset_size Union [ int , dict , float ] int or float, optional, default 0.05 (5% of the data) Coreset size or relative portion of the data to sample. 0.05 coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Corset algorithm specific parameters. None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None","title":"CoresetService"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.build","text":"build ( X , y = None , indices = None ) Create a coreset from a transformed dataset(s). Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None Returns: Type Description CoresetService self","title":"build()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.build_from_df","text":"build_from_df ( datasets , target_datasets = None , ** params ) Create a coreset rom pandas DataFrame(s). Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None Returns: Type Description CoresetService self","title":"build_from_df()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None ) Create a coreset based on the data taken from a local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None Returns: Type Description CoresetService self","title":"build_from_file()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.fit","text":"fit ( model = None , ** model_params ) Train a model for the selected coreset. Parameters: Name Type Description Default model object, optional. A model instance to train with coreset data. None model_params keywords arguments, optional. model initialization parameters. {} Returns: Type Description A trained model.","title":"fit()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.get_coreset","text":"get_coreset () Get coreset indices and weights. Returns: Type Description Tuple [ Iterable , Iterable ] A tuple of indices and weights. indices: a numpy array of selected indices. weights: a numpy array of corresponding weights.","title":"get_coreset()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.get_coreset_data","text":"get_coreset_data ( as_orig = False , with_index = False ) Get coreset data either in a processed format or in the original format. Parameters: Name Type Description Default as_orig boolean, optional, default False Should the data be returned in it's original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description dict dict data: numpy arrays tuple (indices,X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset_data()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.get_important_samples","text":"get_important_samples ( size = None , class_size = None , * , ignore_indices = None , select_from_indices = None ) Returns indices of most important samples order by importance. Useful for identifying miss-labeled instances. At least one of size, class_size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional. An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional. An array of indices to include when selecting important samples. None Returns: Name Type Description tuple Tuple [ Iterable [ int ], Iterable [ float ]] indices: array-like[int]. important samples indices. importance: array-like[float]. The important value. High value is more important.","title":"get_important_samples()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.load","text":"load ( dir_path , name = None , * , data_manager = None , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] Local directory where service data is stored. required name str default service class name (lower case) The name prefix of the sub-directory to load. When more than one sub-directories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen sub-directory is the last saved. None data_manager DataManagerT When specified, input data manger will be used instead of restoring it from the saved configuration. None working_directory Union [ str , os . PathLike ] default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetService CoresetService object","title":"load()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X array an array of features required Returns: Type Description Model prediction results","title":"predict()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.save","text":"save ( dir_path = None , name = None , override = False ) save service configuration and relevant data to a local directory. Use this method when the service needs to restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] default self.working_directory A local directory for saving service's files. None name str default service class name (lower case) Name of the sub-directory where the data will be stored. None override bool False: add a timestamp suffix so each save won\u2019t override previous ones. True: existing sub-directory with that name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetService.save_coreset_data","text":"save_coreset_data ( file_path , as_orig = False , with_index = False ) Save coreset data to a file along with coreset weights. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required as_orig bool boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index bool boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset_data()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetServiceKMeans","text":"Bases: CoresetService Subclass of CoresetService for KMeans","title":"CoresetServiceKMeans"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetServiceLG","text":"Bases: CoresetService","title":"CoresetServiceLG"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetServiceLG.get_coreset","text":"get_coreset ( inverse = True ) Return the indexes and weights. If class_weights is provided and inverse = True the weights will be divided by the class weights, therefore requiring the user to pass class_weights again the fit function. Parameters: Name Type Description Default inverse True - return weights / class_weights False - return weights as they are. True Returns: Type Description Tuple [ Iterable , Iterable ] Tuple[Iterable, Iterable] idxs, weights","title":"get_coreset()"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetServiceLR","text":"Bases: CoresetService Subclass of CoresetService for linear regression","title":"CoresetServiceLR"},{"location":"reference/services/coreset_services/#services.coreset_services.CoresetServicePCA","text":"Bases: CoresetService Subclass of CoresetService for PCA","title":"CoresetServicePCA"},{"location":"reference/services/tree_services/","text":"CoresetTreeService \u00a4 CoresetTreeService ( * , data_manager = None , data_params = None , coreset_size , coreset_params = None , sample_all = None , class_size = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None ) Bases: CoresetServiceBase Service class for creating and working with a coreset tree Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. None coreset_size Union [ int , dict ] int/dict, required Represent the coreset size of each node in the tree. dict {class: size}: control the number of samples to choose for each class. required sample_all Iterable iterable, optional Classification only, a list of classes for them all samples should be taken. When provided, coreset_size must be an int. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Corset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None apply_data_filter \u00a4 apply_data_filter ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, on the base of filter function, that returns list of samples to be left in tree. The signature is filter_function(indexes, X, y) . For example, for removing all instances for which target equal 6, the following function could be defined filter_function = lambda indexes, X, y : indexes[y != 6] . Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ bool ]] Function that returns list of samples to be left in tree. Its logic described above. required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False build \u00a4 build ( X , y = None , indices = None , * , sample_size = None , coreset_by = None ) Create a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self build_from_df \u00a4 build_from_df ( datasets , target_datasets = None , * , sample_size = None , coreset_by = None ) Create a coreset tree from pandas DataFrame(s). Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self build_from_file \u00a4 build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , sample_size = None , coreset_by = None ) Create a coreset tree based on the data taken from a local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None sample_size int int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self build_from_tensor \u00a4 build_from_tensor ( dataset , * , sample_size = None , coreset_by = None ) create a coreset tree based on the torch.Tensor Parameters: Name Type Description Default dataset Any torch.Tensor required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None build_from_tensorflow_dataset \u00a4 build_from_tensorflow_dataset ( dataset , * , sample_size = None , coreset_by = None ) create a coreset tree based on the tf.data.Dataset Parameters: Name Type Description Default dataset Any , Any tuple (tf.data.Dataset, tfds.core.DatasetInfo) required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None explain \u00a4 explain ( X , model_scoring_function ) return leaf metadata and explainability path, using provided unlabeled examples and model scoring function. Parameters: Name Type Description Default X array like unclassified samples required model_scoring_function Callable [[ np . ndarray , Any ], float ] callable[[array like, any], float] model scoring function which gets the X and the node's train model as params and returns a score in the range of [0,1]; this function drives the building of the explainability path. required Returns: Type Description Iterator [ Tuple [ Union [ list , dict ], str , str ]] An iterator of (metadata,explanation) tuples: metadata: selected leaf's metadata explanation: free text explaining the built explainability path fit \u00a4 fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyper parameters kwargs Input when instantiating default model class. {} get_coreset \u00a4 get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in it's original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description dict dict data: numpy arrays tuple (indices,X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset get_important_samples \u00a4 get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , filter_function = None , ignore_seen_samples = True , verbose = False ) Returns indices of most important samples order by importance. Useful for identifying miss-labeled instances. At least one of size, class_size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional. An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional. An array of indices to consider when selecting important samples. None filter_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ Any ]] array-like, optional. Filter results by function. Function should accept 3 parameters as input: indices, X, y and return a list(iterator) of indices None ignore_seen_samples bool bool, optional, default False. Exclude already seen indices and set seen flag on any returned indices. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. important samples indices. X: array-like[int]. X array y: array-like[int]. y array importance: array-like[float]. The important value. High value is more important. Examples \u00a4 Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\" is_dirty \u00a4 is_dirty () Returns a flag whether the coreset tree has \"dirty\" nodes, that is all nodes, that were affected with any of methods: remove_samples, update_targets, update_features, apply_data_filter, and were not resampled. load classmethod \u00a4 load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the sub-directory to load. When more than one sub-directories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen sub-directory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boole, optional, default True If set, load saved buffer from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object partial_build \u00a4 partial_build ( X , y = None , indices = None , * , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self partial_build_from_df \u00a4 partial_build_from_df ( datasets , target_datasets = None , * , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None sample_size int, optional, default previous used sample_size The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self partial_build_from_file \u00a4 partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree based on the data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None sample_size int int, optional, default previous used sample_size The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks. None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self partial_build_from_tensor \u00a4 partial_build_from_tensor ( dataset , * , sample_size = None , coreset_by = None ) Applying new samples to a coreset tree based on the torch.Tensor Parameters: Name Type Description Default dataset Any torch.Tensor required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None partial_build_from_tensorflow_dataset \u00a4 partial_build_from_tensorflow_dataset ( dataset , * , sample_size = None , coreset_by = None ) Applying new samples to a coreset tree based on the tf.data.Dataset Parameters: Name Type Description Default dataset Any , Any tuple (tf.data.Dataset, tfds.core.DatasetInfo) required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None plot \u00a4 plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path predict \u00a4 predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Model prediction results print \u00a4 print () Print the tree's string representation. remove_samples \u00a4 remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable List of samples to be removed. required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False save \u00a4 save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the sub-directory where the data will be stored. None save_buffer bool boolean, default True Save the service\u2019s configuration and relevant data to a local directory. True override bool bool, optional, default false False: add a timestamp suffix so each save won\u2019t override previous ones. True: existing sub-directory with that name is overridden. False Returns: Type Description pathlib . Path Save directory path. save_coreset \u00a4 save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False set_seen_indication \u00a4 set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only on provided list of indices. Defaults to all indices. None update_dirty \u00a4 update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Execute resampling on dirty nodes of the coreset tree, that is all nodes, that were affected with any of methods: remove_samples, update_targets, update_features, apply_data_filter , and were not partially or fully resampled. Parameters: Name Type Description Default force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None update_features \u00a4 update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update features for samples on the coreset tree. Parameters: Name Type Description Default indices Iterable List of samples to be removed. required X Iterable List of features, should have the same length as indices required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False update_targets \u00a4 update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update targets for samples on the coreset tree. Parameters: Name Type Description Default indices Iterable Iterable List of samples to be removed. required y Iterable List of targets, should have the same length as indices required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False CoresetTreeServiceKMeans \u00a4 Bases: CoresetTreeService Subclass of CoresetTreeService for KMeans CoresetTreeServiceLG \u00a4 Bases: CoresetTreeService Subclass of CoresetTreeService for Logistic Regression CoresetTreeServiceLR \u00a4 Bases: CoresetTreeService Subclass of CoresetTreeService for linear regression CoresetTreeServicePCA \u00a4 Bases: CoresetTreeService Subclass of CoresetTreeService for PCA CoresetTreeServiceSVD \u00a4 Bases: CoresetTreeService Subclass of CoresetTreeService for SVD","title":"tree_services"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService","text":"CoresetTreeService ( * , data_manager = None , data_params = None , coreset_size , coreset_params = None , sample_all = None , class_size = None , working_directory = None , cache_dir = None , node_train_function = None , node_train_function_params = None , node_metadata_func = None ) Bases: CoresetServiceBase Service class for creating and working with a coreset tree Parameters: Name Type Description Default data_manager DataManagerT DataManagerBase subclass, optional None data_params Union [ DataParams , dict ] DataParams, optional Preprocessing information. None coreset_size Union [ int , dict ] int/dict, required Represent the coreset size of each node in the tree. dict {class: size}: control the number of samples to choose for each class. required sample_all Iterable iterable, optional Classification only, a list of classes for them all samples should be taken. When provided, coreset_size must be an int. None coreset_params Union [ CoresetParams , dict ] CoresetParams or dict, optional Corset algorithm specific parameters. None node_train_function Callable [[ np . ndarray , np . ndarray , np . ndarray ], Any ] Callable, optional method for training model at tree node level None node_train_function_params dict dict, optional kwargs to be used when calling node_train_function None node_metadata_func Callable [[ Tuple [ np . ndarray ], np . ndarray , Union [ list , None]], Union [ list , dict , None]] callable, optional A method for storing user meta data on each node None working_directory Union [ str , os . PathLike ] str, path, optional Local directory where intermediate data is stored. None cache_dir Union [ str , os . PathLike ] str, path, optional For internal use when loading a saved service. None","title":"CoresetTreeService"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.apply_data_filter","text":"apply_data_filter ( filter_function , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree, on the base of filter function, that returns list of samples to be left in tree. The signature is filter_function(indexes, X, y) . For example, for removing all instances for which target equal 6, the following function could be defined filter_function = lambda indexes, X, y : indexes[y != 6] . Parameters: Name Type Description Default filter_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ bool ]] Function that returns list of samples to be left in tree. Its logic described above. required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False","title":"apply_data_filter()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.build","text":"build ( X , y = None , indices = None , * , sample_size = None , coreset_by = None ) Create a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.build_from_df","text":"build_from_df ( datasets , target_datasets = None , * , sample_size = None , coreset_by = None ) Create a coreset tree from pandas DataFrame(s). Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_df()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.build_from_file","text":"build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , sample_size = None , coreset_by = None ) Create a coreset tree based on the data taken from a local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None sample_size int int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"build_from_file()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.build_from_tensor","text":"build_from_tensor ( dataset , * , sample_size = None , coreset_by = None ) create a coreset tree based on the torch.Tensor Parameters: Name Type Description Default dataset Any torch.Tensor required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None","title":"build_from_tensor()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.build_from_tensorflow_dataset","text":"build_from_tensorflow_dataset ( dataset , * , sample_size = None , coreset_by = None ) create a coreset tree based on the tf.data.Dataset Parameters: Name Type Description Default dataset Any , Any tuple (tf.data.Dataset, tfds.core.DatasetInfo) required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None","title":"build_from_tensorflow_dataset()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.explain","text":"explain ( X , model_scoring_function ) return leaf metadata and explainability path, using provided unlabeled examples and model scoring function. Parameters: Name Type Description Default X array like unclassified samples required model_scoring_function Callable [[ np . ndarray , Any ], float ] callable[[array like, any], float] model scoring function which gets the X and the node's train model as params and returns a score in the range of [0,1]; this function drives the building of the explainability path. required Returns: Type Description Iterator [ Tuple [ Union [ list , dict ], str , str ]] An iterator of (metadata,explanation) tuples: metadata: selected leaf's metadata explanation: free text explaining the built explainability path","title":"explain()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.fit","text":"fit ( level = 0 , model = None , ** model_params ) Fit a model on the coreset tree. Parameters: Name Type Description Default level Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 model an ml model instance, optional When provided, model_params are not relevant. Default: instantiate the service model class using input model_params. None model_params model hyper parameters kwargs Input when instantiating default model class. {}","title":"fit()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.get_coreset","text":"get_coreset ( level = 0 , as_orig = False , with_index = False ) Get tree's coreset data either in a processed format or in the original format. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 as_orig boolean, optional, default False Should the data be returned in it's original format or as a tuple of indices, X, and optionally y. True: data is returned as a pandas DataFrame. False: return a tuple of (indices, X, y) if target was used and (indices, X) when there is no target. False with_index boolean, optional, default False Relevant only when as_orig=True. Should the returned data include the index column. False Returns: Name Type Description dict dict data: numpy arrays tuple (indices,X, optional y) or a pandas DataFrame w: A numpy array of sample weights n_represents: number of instances represented by the coreset","title":"get_coreset()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.get_important_samples","text":"get_important_samples ( size = None , class_size = None , ignore_indices = None , select_from_indices = None , filter_function = None , ignore_seen_samples = True , verbose = False ) Returns indices of most important samples order by importance. Useful for identifying miss-labeled instances. At least one of size, class_size must be provided. Must be called after build. Parameters: Name Type Description Default size int int, optional Number of samples to return. When class_size is provided, remaining samples are taken from classes not appearing in class_size dictionary. None class_size Dict [ Any , Union [ int , str ]] dict {class: int or \"all\" or \"any\"}, optional. Controls the number of samples to choose for each class. int: return at most size \"all\": return all samples. \"any\": limits the returned samples to the specified classes. None ignore_indices Iterable array-like, optional. An array of indices to ignore when selecting important samples. None select_from_indices Iterable array-like, optional. An array of indices to consider when selecting important samples. None filter_function Callable [[ Iterable , Iterable , Iterable ], Iterable [ Any ]] array-like, optional. Filter results by function. Function should accept 3 parameters as input: indices, X, y and return a list(iterator) of indices None ignore_seen_samples bool bool, optional, default False. Exclude already seen indices and set seen flag on any returned indices. True Returns: Name Type Description Dict Union [ ValueError , dict ] indices: array-like[int]. important samples indices. X: array-like[int]. X array y: array-like[int]. y array importance: array-like[float]. The important value. High value is more important.","title":"get_important_samples()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.get_important_samples--examples","text":"Input size=100, class_size={\"class A\": 10, \"class B\": 50, \"class C\": \"all\"} Output 10 of \"class A\", 50 of \"class B\", 12 of \"class C\" (all), 28 of \"class D/E\"","title":"Examples"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.is_dirty","text":"is_dirty () Returns a flag whether the coreset tree has \"dirty\" nodes, that is all nodes, that were affected with any of methods: remove_samples, update_targets, update_features, apply_data_filter, and were not resampled.","title":"is_dirty()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.load","text":"load ( dir_path , name = None , * , data_manager = None , load_buffer = True , working_directory = None ) Restore a service object from a local directory. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] str, path Local directory where service data is stored. required name str string, optional, default service class name (lower case) The name prefix of the sub-directory to load. When more than one sub-directories having the same name prefix are found, the last one, ordered by name, is selected. For example when saving with override=False, the chosen sub-directory is the last saved. None data_manager DataManagerT DataManagerBase subclass, optional When specified, input data manger will be used instead of restoring it from the saved configuration. None load_buffer bool boole, optional, default True If set, load saved buffer from disk and add it to the tree. True working_directory Union [ str , os . PathLike ] str, path, optional, default use working_directory from saved configuration Local directory where intermediate data is stored. None Returns: Type Description CoresetTreeService CoresetTreeService object","title":"load()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.partial_build","text":"partial_build ( X , y = None , indices = None , * , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree from parameters X, y and indices. Parameters: Name Type Description Default X Union [ Iterable , Iterable [ Iterable ]] array like or iterator of arrays like an array or an iterator of features required y Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator of targets None indices Union [ Iterable [ Any ], Iterable [ Iterable [ Any ]]] array like or iterator of arrays like, optional an array or an iterator with indices of X None sample_size int The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.partial_build_from_df","text":"partial_build_from_df ( datasets , target_datasets = None , * , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree based on the pandas DataFrame iterator. Parameters: Name Type Description Default datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator Data includes features, may include labels and may include indices. required target_datasets Union [ Iterator [ pd . DataFrame ], pd . DataFrame ] pandas DataFrame or DataFrame iterator, optional Use when data is split to features and labels. Should include only one column. None sample_size int, optional, default previous used sample_size The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split each dataset by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_df()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.partial_build_from_file","text":"partial_build_from_file ( file_path , target_file_path = None , * , reader_f = pd . read_csv , reader_kwargs = None , sample_size = None , coreset_by = None ) Adding new samples to a coreset tree based on the data taken from local storage. Parameters: Name Type Description Default file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories. Path(s) to the place where data is stored. Data includes features, may include labels and may include indices. required target_file_path Union [ Union [ str , os . PathLike ], Iterable [ Union [ str , os . PathLike ]]] file, list of files, directory, list of directories, optional Use when files are split to features and labels. Each file should include only one column. None reader_f pandas like read method, optional, default pandas read_csv For example, to read excel files use pandas read_excel. pd.read_csv reader_kwargs dict dict, optional Keyword arguments used when calling reader_f method. None sample_size int int, optional, default previous used sample_size The number of instances used when creating a coreset node in the tree. sample_size=0: nodes are created based on input chunks. None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional Split the data by the key. When provided, sample_size input is ignored. None Returns: Type Description CoresetTreeService self","title":"partial_build_from_file()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.partial_build_from_tensor","text":"partial_build_from_tensor ( dataset , * , sample_size = None , coreset_by = None ) Applying new samples to a coreset tree based on the torch.Tensor Parameters: Name Type Description Default dataset Any torch.Tensor required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None","title":"partial_build_from_tensor()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.partial_build_from_tensorflow_dataset","text":"partial_build_from_tensorflow_dataset ( dataset , * , sample_size = None , coreset_by = None ) Applying new samples to a coreset tree based on the tf.data.Dataset Parameters: Name Type Description Default dataset Any , Any tuple (tf.data.Dataset, tfds.core.DatasetInfo) required sample_size int nodes are created based on input chunks default: sample_size is decided internally None coreset_by Union [ Callable , str , list ] function, label, or list of labels, optional split each dataset by key None","title":"partial_build_from_tensorflow_dataset()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.plot","text":"plot ( dir_path = None , name = None ) Produce a tree graph plot and save figure as a local png file. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike Path to save the plot figure in; if not provided, or if isn't valid/doesn't exist, the figure will be saved in the current directory (from which this method is called). None name str string, optional Name of the image file None Returns: Type Description pathlib . Path Image file path","title":"plot()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.predict","text":"predict ( X ) Run prediction on the trained model. Parameters: Name Type Description Default X an array of features required Returns: Type Description Model prediction results","title":"predict()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.print","text":"print () Print the tree's string representation.","title":"print()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.remove_samples","text":"remove_samples ( indices , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Remove samples from the coreset tree. Parameters: Name Type Description Default indices Iterable List of samples to be removed. required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False","title":"remove_samples()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.save","text":"save ( dir_path = None , name = None , save_buffer = True , override = False ) Save service configuration and relevant data to a local directory. Use this method when the service needs to restored. Parameters: Name Type Description Default dir_path Union [ str , os . PathLike ] string or PathLike, optional, default self.working_directory A local directory for saving service's files. None name str string, optional, default service class name (lower case) Name of the sub-directory where the data will be stored. None save_buffer bool boolean, default True Save the service\u2019s configuration and relevant data to a local directory. True override bool bool, optional, default false False: add a timestamp suffix so each save won\u2019t override previous ones. True: existing sub-directory with that name is overridden. False Returns: Type Description pathlib . Path Save directory path.","title":"save()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.save_coreset","text":"save_coreset ( file_path , level = 0 , as_orig = False , with_index = False ) Get coreset from the tree and save to a file along with coreset weights. Use the level parameter to control the level of the tree from which samples will be returned. Parameters: Name Type Description Default file_path string or PathLike Local file path to store the coreset. required level int, optional, default 0 Defines the depth level of the tree from which the coreset is extracted. Level 0 returns the coreset from the head of the tree with up to coreset_size samples. Level 1 returns the coreset from the level below the head of the tree with up to 2* coreset_size samples, etc. 0 as_orig boolean, optional, default False True: save in the original format. False: save in a processed format (indices, X, y, weight). False with_index boolean, optional, default False Relevant only when as_orig=True. Save also index column. False","title":"save_coreset()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.set_seen_indication","text":"set_seen_indication ( seen_flag = True , indices = None ) Set samples as 'seen' or 'unseen'. Not providing an indices list defaults to setting the flag on all samples. Parameters: Name Type Description Default seen_flag bool bool Set 'seen' or 'unseen' flag True indices Iterable array like Set flag only on provided list of indices. Defaults to all indices. None","title":"set_seen_indication()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.update_dirty","text":"update_dirty ( force_resample_all = None , force_sensitivity_recalc = None ) Execute resampling on dirty nodes of the coreset tree, that is all nodes, that were affected with any of methods: remove_samples, update_targets, update_features, apply_data_filter , and were not partially or fully resampled. Parameters: Name Type Description Default force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None","title":"update_dirty()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.update_features","text":"update_features ( indices , X , feature_names = None , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update features for samples on the coreset tree. Parameters: Name Type Description Default indices Iterable List of samples to be removed. required X Iterable List of features, should have the same length as indices required feature_names Iterable [ str ] If the quantity of features in X is not equal to the quantity of features in the original coreset, this param should contain list of names of passed features. None force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False","title":"update_features()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeService.update_targets","text":"update_targets ( indices , y , force_resample_all = None , force_sensitivity_recalc = None , force_do_nothing = False ) Update targets for samples on the coreset tree. Parameters: Name Type Description Default indices Iterable Iterable List of samples to be removed. required y Iterable List of targets, should have the same length as indices required force_resample_all int Force full resample for affected nodes, starting from level=force_resample_all, assuming: 0 - root level; len(tree) = leaf level; None - no force resample at all; -1 - same as leaf level. None force_sensitivity_recalc int Partial resampling for affected nodes, based on coreset quality, starting from level=force_sensitivity_recalc, assuming: 0 - root level; len(tree) - leaf level; None - one level above leaf (same as force_sensitivity_recalc=len(tree)-1, default behaviour); -1 - same as leaf level None force_do_nothing bool bool, default False If set True - do not make either full or partial resampling False","title":"update_targets()"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeServiceKMeans","text":"Bases: CoresetTreeService Subclass of CoresetTreeService for KMeans","title":"CoresetTreeServiceKMeans"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeServiceLG","text":"Bases: CoresetTreeService Subclass of CoresetTreeService for Logistic Regression","title":"CoresetTreeServiceLG"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeServiceLR","text":"Bases: CoresetTreeService Subclass of CoresetTreeService for linear regression","title":"CoresetTreeServiceLR"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeServicePCA","text":"Bases: CoresetTreeService Subclass of CoresetTreeService for PCA","title":"CoresetTreeServicePCA"},{"location":"reference/services/tree_services/#services.tree_services.CoresetTreeServiceSVD","text":"Bases: CoresetTreeService Subclass of CoresetTreeService for SVD","title":"CoresetTreeServiceSVD"},{"location":"coverage/","text":"article h1, article > a, .md-sidebar--secondary { display: none !important; } var coviframe = document.getElementById(\"coviframe\"); function resizeIframe() { coviframe.style.height = coviframe.contentWindow.document.documentElement.offsetHeight + 'px'; } coviframe.contentWindow.document.body.onclick = function() { coviframe.contentWindow.location.reload(); }","title":"Coverage"}]}